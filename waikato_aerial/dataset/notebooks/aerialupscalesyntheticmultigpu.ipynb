{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall torch torchvision torchaudio fastai -y","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-25T15:24:34.476710Z","iopub.execute_input":"2025-02-25T15:24:34.477020Z","iopub.status.idle":"2025-02-25T15:25:11.065069Z","shell.execute_reply.started":"2025-02-25T15:24:34.476993Z","shell.execute_reply":"2025-02-25T15:25:11.064032Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Found existing installation: torch 2.5.1+cu121\nUninstalling torch-2.5.1+cu121:\n  Successfully uninstalled torch-2.5.1+cu121\nFound existing installation: torchvision 0.20.1+cu121\nUninstalling torchvision-0.20.1+cu121:\n  Successfully uninstalled torchvision-0.20.1+cu121\nFound existing installation: torchaudio 2.5.1+cu121\nUninstalling torchaudio-2.5.1+cu121:\n  Successfully uninstalled torchaudio-2.5.1+cu121\nFound existing installation: fastai 2.7.18\nUninstalling fastai-2.7.18:\n  Successfully uninstalled fastai-2.7.18\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install diffusers==0.32.2 xformers torchvision torchaudio fastai --no-cache-dir","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T15:25:11.066480Z","iopub.execute_input":"2025-02-25T15:25:11.066756Z","iopub.status.idle":"2025-02-25T15:26:53.097876Z","shell.execute_reply.started":"2025-02-25T15:25:11.066733Z","shell.execute_reply":"2025-02-25T15:26:53.096791Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting diffusers==0.32.2\n  Downloading diffusers-0.32.2-py3-none-any.whl.metadata (18 kB)\nCollecting xformers\n  Downloading xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nCollecting torchvision\n  Downloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\nCollecting torchaudio\n  Downloading torchaudio-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\nCollecting fastai\n  Downloading fastai-2.7.18-py3-none-any.whl.metadata (9.1 kB)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.32.2) (8.5.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.32.2) (3.17.0)\nRequirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.32.2) (0.29.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.32.2) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.32.2) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.32.2) (2.32.3)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.32.2) (0.4.5)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.32.2) (11.0.0)\nCollecting torch==2.6.0 (from xformers)\n  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->xformers) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->xformers) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->xformers) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->xformers) (2024.12.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->xformers)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->xformers)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->xformers)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->xformers)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->xformers)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->xformers)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->xformers)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->xformers)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->xformers)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0->xformers)\n  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.21.5 (from torch==2.6.0->xformers)\n  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.4.127 (from torch==2.6.0->xformers)\n  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->xformers)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting triton==3.2.0 (from torch==2.6.0->xformers)\n  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0->xformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.6.0->xformers) (1.3.0)\nRequirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai) (24.1.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastai) (24.2)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai) (0.0.7)\nRequirement already satisfied: fastcore<1.8,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai) (1.7.27)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fastai) (3.7.5)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fastai) (2.2.3)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from fastai) (6.0.2)\nRequirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai) (1.0.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fastai) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fastai) (1.13.1)\nRequirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai) (3.7.5)\nINFO: pip is looking at multiple versions of fastai to determine which version is compatible with other requirements. This could take a while.\nCollecting fastai\n  Downloading fastai-2.7.17-py3-none-any.whl.metadata (9.1 kB)\n  Downloading fastai-2.7.16-py3-none-any.whl.metadata (9.1 kB)\nCollecting fastcore<1.6,>=1.5.29 (from fastai)\n  Downloading fastcore-1.5.55-py3-none-any.whl.metadata (3.5 kB)\nCollecting fastai\n  Downloading fastai-2.7.15-py3-none-any.whl.metadata (9.1 kB)\n  Downloading fastai-2.7.14-py3-none-any.whl.metadata (9.1 kB)\n  Downloading fastai-2.7.13-py3-none-any.whl.metadata (9.6 kB)\n  Downloading fastai-2.7.12-py3-none-any.whl.metadata (9.6 kB)\n  Downloading fastai-2.7.11-py3-none-any.whl.metadata (9.6 kB)\nINFO: pip is still looking at multiple versions of fastai to determine which version is compatible with other requirements. This could take a while.\n  Downloading fastai-2.7.10-py3-none-any.whl.metadata (9.6 kB)\n  Downloading fastai-2.7.9-py3-none-any.whl.metadata (10 kB)\n  Downloading fastai-2.7.8-py3-none-any.whl.metadata (10 kB)\n  Downloading fastai-2.7.7-py3-none-any.whl.metadata (10 kB)\n  Downloading fastai-2.7.6-py3-none-any.whl.metadata (10 kB)\nCollecting fastcore<1.5,>=1.4.5 (from fastai)\n  Downloading fastcore-1.4.5-py3-none-any.whl.metadata (16 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\nCollecting fastai\n  Downloading fastai-2.7.5-py3-none-any.whl.metadata (10 kB)\n  Downloading fastai-2.7.4-py3-none-any.whl.metadata (10 kB)\n  Downloading fastai-2.7.3-py3-none-any.whl.metadata (10 kB)\n  Downloading fastai-2.7.2-py3-none-any.whl.metadata (10 kB)\n  Downloading fastai-2.7.1-py3-none-any.whl.metadata (10 kB)\n  Downloading fastai-2.7.0-py3-none-any.whl.metadata (10 kB)\n  Downloading fastai-2.6.3-py3-none-any.whl.metadata (10 kB)\n  Downloading fastai-2.6.2-py3-none-any.whl.metadata (10 kB)\n  Downloading fastai-2.6.1-py3-none-any.whl.metadata (10 kB)\n  Downloading fastai-2.6.0-py3-none-any.whl.metadata (10 kB)\n  Downloading fastai-2.5.6-py3-none-any.whl.metadata (10.0 kB)\n  Downloading fastai-2.5.5-py3-none-any.whl.metadata (10 kB)\n  Downloading fastai-2.5.4-py3-none-any.whl.metadata (10 kB)\nCollecting fastcore<1.4,>=1.3.27 (from fastai)\n  Downloading fastcore-1.3.29-py3-none-any.whl.metadata (16 kB)\nCollecting fastai\n  Downloading fastai-2.5.3-py3-none-any.whl.metadata (9.9 kB)\n  Downloading fastai-2.5.2-py3-none-any.whl.metadata (9.9 kB)\n  Downloading fastai-2.5.1-py3-none-any.whl.metadata (9.9 kB)\n  Downloading fastai-2.5.0-py3-none-any.whl.metadata (9.8 kB)\n  Downloading fastai-2.4.1-py3-none-any.whl.metadata (9.8 kB)\n  Downloading fastai-2.4-py3-none-any.whl.metadata (9.8 kB)\n  Downloading fastai-2.3.1-py3-none-any.whl.metadata (9.8 kB)\n  Downloading fastai-2.3.0-py3-none-any.whl.metadata (9.2 kB)\n  Downloading fastai-2.2.7-py3-none-any.whl.metadata (9.2 kB)\n  Downloading fastai-2.2.6-py3-none-any.whl.metadata (9.2 kB)\n  Downloading fastai-2.2.5-py3-none-any.whl.metadata (9.1 kB)\n  Downloading fastai-2.2.4-py3-none-any.whl.metadata (9.1 kB)\n  Downloading fastai-2.2.3-py3-none-any.whl.metadata (9.1 kB)\n  Downloading fastai-2.2.2-py3-none-any.whl.metadata (9.1 kB)\n  Downloading fastai-2.2.1-py3-none-any.whl.metadata (9.1 kB)\n  Downloading fastai-2.2.0-py3-none-any.whl.metadata (9.1 kB)\n  Downloading fastai-2.1.10-py3-none-any.whl.metadata (9.1 kB)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.32.2) (4.67.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.32.2) (3.21.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (1.4.7)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->diffusers==0.32.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->diffusers==0.32.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->diffusers==0.32.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->diffusers==0.32.2) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->diffusers==0.32.2) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->diffusers==0.32.2) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fastai) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->fastai) (2025.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.32.2) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.32.2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.32.2) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.32.2) (2025.1.31)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastai) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastai) (3.5.0)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.0.11)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.0.10)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.5.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (0.15.1)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.11.0a2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (75.1.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.5.0)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai) (1.3.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (2.29.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.17.0)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai) (13.9.4)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai) (7.0.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.6.0->xformers) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->diffusers==0.32.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->diffusers==0.32.2) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->diffusers==0.32.2) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->diffusers==0.32.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->diffusers==0.32.2) (2024.2.0)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4->fastai) (1.17.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai) (0.1.2)\nDownloading diffusers-0.32.2-py3-none-any.whl (3.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl (43.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 MB\u001b[0m \u001b[31m273.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m275.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m279.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m228.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m217.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m344.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m260.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m265.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m226.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m162.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m272.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m285.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m265.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m235.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m263.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m238.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m223.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchaudio-2.6.0-cp310-cp310-manylinux1_x86_64.whl (3.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m221.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastai-2.1.10-py3-none-any.whl (190 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.4/190.4 kB\u001b[0m \u001b[31m330.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchaudio, torchvision, xformers, fastai, diffusers\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.23.4\n    Uninstalling nvidia-nccl-cu12-2.23.4:\n      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: diffusers\n    Found existing installation: diffusers 0.31.0\n    Uninstalling diffusers-0.31.0:\n      Successfully uninstalled diffusers-0.31.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed diffusers-0.32.2 fastai-2.1.10 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 torch-2.6.0 torchaudio-2.6.0 torchvision-0.21.0 triton-3.2.0 xformers-0.0.29.post3\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install accelerate>=0.16.0 torchvision transformers>=4.25.1 ftfy tensorboard Jinja2 peft==0.7.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T15:26:53.099386Z","iopub.execute_input":"2025-02-25T15:26:53.099696Z","iopub.status.idle":"2025-02-25T15:26:57.407390Z","shell.execute_reply.started":"2025-02-25T15:26:53.099672Z","shell.execute_reply":"2025-02-25T15:26:57.406343Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Image upscaling with true parallel multi-GPU support\n# model: stabilityai/stable-diffusion-x4-upscaler\n\nfrom datasets import load_dataset\nfrom diffusers import StableDiffusionUpscalePipeline\nimport torch\nimport gc\nfrom tqdm import tqdm\nimport concurrent.futures\nimport threading\nimport time\nimport os\nfrom functools import partial\n\nclasses = {\n    'broadleaved_indigenous_hardwood': 'BIH', \n    'deciduous_hardwood': 'DHW', \n    'grose_broom': 'GBM', \n    'harvested_forest': 'HFT', \n    'herbaceous_freshwater_vege': 'HFV', \n    'high_producing_grassland': 'HPG', \n    'indigenous_forest': 'IFT', \n    'lake_pond': 'LPD', \n    'low_producing_grassland': 'LPG', \n    'manuka_kanuka': 'MKA', \n    'shortrotation_cropland': 'SRC', \n    'urban_build_up': 'UBU', \n    'urban_parkland': 'UPL'\n}\n\n# Global variables for GPU management\ngpu_locks = []\npipelines = []\n\ndef setup_multi_pipeline():\n    \"\"\"\n    Set up multiple pipelines, one per GPU with proper locking mechanisms.\n    \"\"\"\n    global gpu_locks, pipelines\n    \n    model_id = \"stabilityai/stable-diffusion-x4-upscaler\"\n    num_gpus = torch.cuda.device_count()\n    \n    if num_gpus <= 0:\n        raise RuntimeError(\"No CUDA devices available\")\n    \n    print(f\"Found {num_gpus} GPU(s)\")\n    \n    # Create locks and pipelines for each GPU\n    gpu_locks = [threading.Lock() for _ in range(num_gpus)]\n    pipelines = []\n    \n    for i in range(num_gpus):\n        print(f\"Setting up pipeline on GPU {i}\")\n        pipe = StableDiffusionUpscalePipeline.from_pretrained(\n            model_id,\n            torch_dtype=torch.float16\n        )\n        pipe = pipe.to(f\"cuda:{i}\")\n        pipelines.append(pipe)\n    \n    print(f\"Created {len(pipelines)} pipelines across {num_gpus} GPUs\")\n    return num_gpus\n\ndef process_batch_on_gpu(batch_data, gpu_idx, int2str_fn):\n    \"\"\"Process a batch of examples on a specific GPU.\"\"\"\n    global gpu_locks, pipelines\n    \n    results = []\n    batch_indices, batch_examples = batch_data\n    \n    # Acquire lock for this GPU\n    with gpu_locks[gpu_idx]:\n        pipeline = pipelines[gpu_idx]\n        \n        for idx, example in zip(batch_indices, batch_examples):\n            image = example[\"image\"]\n            label = example[\"label\"]\n            \n            # Get the string label\n            label_str = int2str_fn(label)\n            \n            # Resize the image\n            low_res_image = image.resize((128, 128))\n            \n            # Create prompt\n            label_parts = label_str.split(\"_\")\n            prompt = f\"A real aerial view of {' '.join(label_parts)} area in Waikato, New Zealand\"\n            \n            # Upscale the image using the selected pipeline\n            try:\n                upscaled_image = pipeline(prompt=prompt, image=low_res_image).images[0]\n                \n                # Create result with upscaled image\n                result = dict(example)\n                result[\"image\"] = upscaled_image\n                results.append((idx, result))\n            except Exception as e:\n                print(f\"Error processing image {idx} on GPU {gpu_idx}: {str(e)}\")\n                # Return original in case of error\n                results.append((idx, example))\n    \n    return results\n\ndef upscale(dataset_name: str, version: str, huggingface_token: str) -> None:\n    \"\"\"Upscale the dataset using multiple GPUs in parallel.\"\"\"\n    full_dataset_name = f\"{dataset_name}{version}\"\n    print(f\"Loading dataset: {full_dataset_name}\")\n    \n    synthetic_ds = load_dataset(full_dataset_name, token=huggingface_token)\n    \n    # Set up multiple pipelines\n    num_gpus = setup_multi_pipeline()\n    \n    # Process each split\n    for split in synthetic_ds:\n        print(f\"Processing {split} split with {len(synthetic_ds[split])} samples\")\n        \n        # Get the int2str function for labels\n        int2str_fn = synthetic_ds[split].features[\"label\"].int2str\n        \n        # Define batch size and prepare batches\n        # Smaller batches to avoid memory issues, but not too small to maintain parallelism\n        batch_size = 4  # Can be adjusted based on your GPU memory\n        total_samples = len(synthetic_ds[split])\n        \n        # Create batches\n        batches = []\n        for i in range(0, total_samples, batch_size):\n            end_idx = min(i + batch_size, total_samples)\n            batch_indices = list(range(i, end_idx))\n            batch_examples = [synthetic_ds[split][j] for j in batch_indices]\n            batches.append((batch_indices, batch_examples))\n        \n        print(f\"Created {len(batches)} batches of size {batch_size}\")\n        \n        # Process batches in parallel using ThreadPoolExecutor\n        processed_results = []\n        with concurrent.futures.ThreadPoolExecutor(max_workers=num_gpus) as executor:\n            # Submit each batch to a GPU\n            futures = []\n            for i, batch in enumerate(batches):\n                gpu_idx = i % num_gpus\n                # Use partial to create a function with bound arguments\n                process_fn = partial(process_batch_on_gpu, batch, gpu_idx, int2str_fn)\n                futures.append(executor.submit(process_fn))\n            \n            # Process results as they complete\n            for i, future in enumerate(tqdm(concurrent.futures.as_completed(futures), \n                                          total=len(futures), \n                                          desc=\"Processing batches\")):\n                try:\n                    batch_results = future.result()\n                    processed_results.extend(batch_results)\n                    \n                    # Periodically clear CUDA cache\n                    if i % 10 == 0:\n                        torch.cuda.empty_cache()\n                except Exception as e:\n                    print(f\"Batch processing error: {str(e)}\")\n        \n        # Sort results by index and extract only the examples\n        processed_results.sort(key=lambda x: x[0])\n        sorted_results = [result for _, result in processed_results]\n        \n        # Create a new dataset from the processed results\n        upscaled_ds = synthetic_ds[split].from_list(sorted_results)\n        synthetic_ds[split] = upscaled_ds\n    \n    # Clean up GPU memory\n    global pipelines\n    for pipeline in pipelines:\n        del pipeline\n    pipelines = []\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    # Push to hub\n    output_name = f\"{full_dataset_name}_upscaled\"\n    print(f\"Pushing to hub: {output_name}\")\n    synthetic_ds.push_to_hub(output_name, token=huggingface_token)\n    print(\"Processing complete!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T15:26:57.408562Z","iopub.execute_input":"2025-02-25T15:26:57.408834Z","iopub.status.idle":"2025-02-25T15:27:16.515349Z","shell.execute_reply.started":"2025-02-25T15:26:57.408800Z","shell.execute_reply":"2025-02-25T15:27:16.514697Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"442899d4088f44b39dbea34f526e706d"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nHFT = user_secrets.get_secret(\"HFT\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T15:27:16.516455Z","iopub.execute_input":"2025-02-25T15:27:16.517054Z","iopub.status.idle":"2025-02-25T15:27:16.684193Z","shell.execute_reply.started":"2025-02-25T15:27:16.517030Z","shell.execute_reply":"2025-02-25T15:27:16.683639Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"upscale(\n    dataset_name=\"dushj98/waikato_aerial_2017_synthetic\", \n    version=\"_v1\", \n    huggingface_token=HFT,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"___","metadata":{}},{"cell_type":"markdown","source":"# Using Accelerate and Xformers","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\nfrom diffusers import StableDiffusionUpscalePipeline\nimport torch\nfrom torch.nn import DataParallel\nfrom torchvision.transforms import ToTensor, ToPILImage\n\n# Define classes\nclasses = {\n    'broadleaved_indigenous_hardwood': 'BIH', \n    'deciduous_hardwood': 'DHW', \n    'grose_broom': 'GBM', \n    'harvested_forest': 'HFT', \n    'herbaceous_freshwater_vege': 'HFV', \n    'high_producing_grassland': 'HPG', \n    'indigenous_forest': 'IFT', \n    'lake_pond': 'LPD', \n    'low_producing_grassland': 'LPG', \n    'manuka_kanuka': 'MKA', \n    'shortrotation_cropland': 'SRC', \n    'urban_build_up': 'UBU', \n    'urban_parkland': 'UPL'\n}\n\n# Load the model\nmodel_id = \"stabilityai/stable-diffusion-x4-upscaler\"\npipeline = StableDiffusionUpscalePipeline.from_pretrained(\n    model_id, \n    torch_dtype=torch.float16\n)\n\n# Enable xFormers for memory efficiency and speed (if installed)\ntry:\n    pipeline.enable_xformers_memory_efficient_attention()\nexcept ImportError:\n    print(\"xFormers not installed. Skipping memory-efficient attention.\")\n\n# Move the pipeline to the GPU and wrap it with DataParallel\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n    pipeline = DataParallel(pipeline.to(\"cuda\"))\nelse:\n    pipeline = pipeline.to(\"cuda\")\n\n# Define transforms for converting PIL images to tensors and back\nto_tensor = ToTensor()\nto_pil = ToPILImage()\n\ndef _upscale_batch(batch, int2str):\n    \"\"\"\n    Processes a batch of images and labels.\n    \"\"\"\n    images = batch[\"image\"]\n    labels = batch[\"label\"]\n    label_strings = [int2str(label) for label in labels]\n\n    # Resize images to low resolution and convert to tensors\n    low_res_images = [to_tensor(image.resize((128, 128))) for image in images]\n\n    # Generate prompts for the batch\n    prompts = [\n        f\"A real aerial view of {' '.join(label_str.split('_'))} area in Waikato, New Zealand\"\n        for label_str in label_strings\n    ]\n\n    # Perform upscaling for the batch\n    upscaled_images = []\n    for prompt, low_res_image in zip(prompts, low_res_images):\n        with torch.no_grad():\n            # Convert tensor back to PIL for the pipeline\n            low_res_pil = to_pil(low_res_image)\n            # Move the PIL image to the correct device (handled by DataParallel)\n            if torch.cuda.device_count() > 1:\n                upscaled_image = pipeline.module(prompt=prompt, image=low_res_pil).images[0]\n            else:\n                upscaled_image = pipeline(prompt=prompt, image=low_res_pil).images[0]\n            upscaled_images.append(upscaled_image)  # PIL image, no need to move to CPU\n\n    # Update the batch with upscaled images\n    batch[\"image\"] = upscaled_images\n    \n    return batch\n\n\ndef _upscale(dataset_name: str, version: str, huggingface_token: str) -> None:\n    dataset_name = f\"{dataset_name}{version}\"\n    synthetic_ds = load_dataset(dataset_name, token=huggingface_token)\n\n    # Use `map` to handle batched processing\n    synthetic_ds = synthetic_ds.map(\n        _upscale_batch, \n        fn_kwargs={\"int2str\": synthetic_ds[\"train\"].features[\"label\"].int2str},\n        batched=True,  # Process images in batches\n        batch_size=4   # Adjust batch size based on GPU memory\n    )\n\n    # Push the upscaled dataset to the Hub\n    synthetic_ds.push_to_hub(f\"{dataset_name}{version}_upscaled\", token=huggingface_token)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T15:42:22.169977Z","iopub.execute_input":"2025-02-25T15:42:22.170277Z","iopub.status.idle":"2025-02-25T15:42:24.606574Z","shell.execute_reply.started":"2025-02-25T15:42:22.170255Z","shell.execute_reply":"2025-02-25T15:42:24.605629Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cfae9d81b2f4188a5ab26348347362f"}},"metadata":{}},{"name":"stdout","text":"Using 2 GPUs!\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"try:\n    _upscale(\n        dataset_name=\"dushj98/waikato_aerial_2017_synthetic\", \n        version=\"_v1\", \n        huggingface_token=HFT\n    )\nexcept KeyboardInterrupt:\n    print(\"Stopped via a Keyboard Interrupt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T15:45:12.382578Z","iopub.execute_input":"2025-02-25T15:45:12.382875Z","iopub.status.idle":"2025-02-25T15:46:24.456322Z","shell.execute_reply.started":"2025-02-25T15:45:12.382853Z","shell.execute_reply":"2025-02-25T15:46:24.455616Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24e955d7e7f24d19a7673ec33582cb6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/75 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f032afd59a64bbea95d75adaf624b04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/75 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dd1f083bc27458fb23fc24caf713ea4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/75 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d5cfea39ae841bd9a6781ae3e35dae4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/75 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1aba210ba7642018b16a2fafbbf5fa6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/75 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15ccd69b19b946e89274ca374c804ed3"}},"metadata":{}},{"name":"stdout","text":"Stopped via a Keyboard Interrupt\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"___","metadata":{}}]}