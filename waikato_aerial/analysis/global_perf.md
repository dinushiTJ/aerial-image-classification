## RESULTS
% Looking at the Figures 1, 4, and 7, it is evident that FFT and PFT has performed better with lower loss values than FE. FFT has led to best performance across all three models as the synthetic data proportion systematically increased.

% Transfer Learning Mode Behaviour
% ---
% Out of all three models ViT-B/16 model is the best performing model on the real-only dataset across FE (0.462 ± 0.003) and FFT (0.527 ± 0.004), establishing a robust baseline. However, as synthetic data proportion increases, ViT-B/16 performance has gradually decreased overtime. EfficientNet B2 is the second best performing baseline with a FFT performance of 0.524 ± 0.004, closely following the ViT-B/16 model, making ResNet-50 the worst performing baseline out of the three classifiers with FFT performance at 0.499 ± 0.004.

% (Full fine-tuning (FFT) consistently achieved the highest validation accuracies across all architectures and synthetic data proportions. ViT-B/16 with FFT demonstrated superior performance, achieving 0.527 ± 0.004 accuracy on the real dataset and maintaining competitive performance even at high synthetic proportions (0.519 ± 0.003 at p150). EfficientNet-B2 with FFT showed comparable performance, achieving 0.524 ± 0.004 on real data and 0.519 ± 0.002 at p150.
% Partial fine-tuning (PFT) modes exhibited intermediate performance levels, with accuracies typically ranging between 0.480-0.512 across all architectures and synthetic proportions. Notably, PFT showed remarkable stability across synthetic data augmentation levels, with minimal performance variation.
% Feature extraction (FE) modes consistently yielded the lowest accuracies, with performance ranging from 0.362-0.462. FE modes also demonstrated the most pronounced sensitivity to synthetic data augmentation, showing clear degradation patterns as synthetic proportions increased.)


% Classifer Performance Behavior
% ----
% However, when it comes to benefitting from increasing synthetic data proportions, different model architectures behave in different ways. In ViT-B/16, all FE, PFT, and FFT shows an immediate decline without any gains from synthetic data; FE, PFT and FFT accuracy decreases consistantly by 0.0276, 0.0026, and 0.0087, respectively (FFT and PFT decreases are very slight, suggesting a little stable performance for added synthetic data with minor fluctuations). However, ResNet-50 shows gains for small proportions of synthetic data across all three modes: FE shows accuracy gains from p10 (max gain: 0.0086 ) to p50, however gain is gradually decreasing and does not benefit when the proportion exceeds p50. for Resnet-50 PFT and FFT, gains are there until p75, but goes to minus range when synthetic data proportion exceeds p75. Suggesting a saturation point around p50 - p75 for ResNet-50. For EfficientNet B2, FE doesnt benefit at all and immediately accuracy decreases (by 0.0421 at p150), whereas PFT and FFT slightly benefit from p10 (very small gain, PFT 0.0011, FFT: 0.0006) but decreases when the synthetic data proportion exceeds p10. However for all three models FFT and PFT shows stable performance with only minor decreases than FE.

% The loss results mirrored the accuracy trends. FE modes generally showed an increase in loss with higher synthetic data proportions. For instance, ViT-B/16 (FE) loss increased from 1.634±0.004 to 1.708±0.005. Conversely, FFT modes maintained relatively stable and low loss values across the different synthetic data proportions, indicative of better model generalization. (Feature extraction modes exhibited the highest losses, with values increasing substantially as synthetic proportions grew. The loss trends reinforced the accuracy findings, confirming that FFT modes maintained better optimization landscapes even with increased synthetic data proportions.)



## DISCUSSION
The results of this study clearly demonstrate that the effectiveness of synthetic data augmentation is highly dependent on the chosen transfer learning strategy. Full Fine-tuning (FFT) consistently outperformed Feature Extraction (FE) and Partial Fine-tuning (PFT) across all classifier architectures and synthetic data proportions. This suggests that allowing the model to adapt all its layers to the augmented dataset is crucial for leveraging the benefits of synthetic data, rather than relying solely on pre-trained features."

"The observed degradation in performance for Feature Extraction (FE) modes with increasing synthetic data suggests that the pre-trained features, while effective on the real data, become less discriminative or even detrimental as the dataset incorporates more synthetically generated samples. This could be attributed to a growing divergence between the feature space learned by the pre-trained model and the feature characteristics introduced by the synthetic data. The fixed nature of FE prevents the model from adapting to these new variations, leading to a decline in generalization."

"Conversely, the stability and relatively high performance of PFT and FFT, particularly FFT, indicate that these modes successfully integrate the synthetic data. By fine-tuning a portion or all of the pre-trained weights, the models can learn to extract features that are more robust to the combined real and synthetic data distribution. The ViT-B/16 architecture, when fully fine-tuned, demonstrated remarkable resilience to varying synthetic data proportions, often maintaining its peak performance even at higher augmentation levels (e.g., p150). This may be due to the inherent flexibility of Transformer architectures in learning complex, long-range dependencies, allowing them to better assimilate diverse data characteristics introduced by synthetic samples."

"While synthetic data augmentation can be a powerful tool for improving model performance, our findings suggest that there might be diminishing returns or even negative impacts if the synthetic data proportion becomes excessively large, especially when the model's capacity to adapt is limited (e.g., in FE). For fine-tuning approaches, the slight fluctuations observed at higher synthetic proportions (e.g., p125, p150) could imply that beyond a certain point, the synthetic data might introduce some level of noise or artifacts that slightly perturb the optimal learning trajectory, even if the overall performance remains strong."

"A limitation of this study is that it focused on a specific method of synthetic data generation and a particular set of classification architectures. Future work could explore the impact of different synthetic data generation techniques (e.g., GANs, diffusion models) and their interaction with various transfer learning strategies. Additionally, analyzing the qualitative characteristics of the synthetic data at different proportions and their influence on learned features could provide deeper insights into the observed performance variations.